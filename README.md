# bq2bq-dbt-docker

> **Documentation Technique** : Projet dbt Cloud Run (Architecture Generic Runner)

Ce document dÃ©taille l'architecture technique pour l'ingestion de donnÃ©es BigQuery et la notification d'API via Cloud Run.

---

## ðŸ“ Table des matiÃ¨res

1. [Structure et Logique des DonnÃ©es](#1-structure-et-logique-des-donnÃ©es-dbt--sql)
2. [Gestion des DÃ©pendances](#2-gestion-des-dÃ©pendances--environnement-uv)
3. [SÃ©curitÃ© & Authentification API](#3-sÃ©curitÃ©--authentification-api-secret-token)
4. [Workflow "Generic Runner"](#4-workflow-generic-runner-download-on-start)
5. [Configuration des RequÃªtes SQL](#5-configuration-des-requÃªtes-sql)
6. [Wrapper Python (Orchestrateur)](#6-le-wrapper-python-lorchÃ©strateur)
7. [Conteneurisation Docker](#7-conteneurisation-docker)
8. [Infrastructure Terraform & Cloud Run](#8-infrastructure-terraform--cloud-run)

---

## 1. Structure et Logique des DonnÃ©es (dbt + SQL)

Au lieu de scripts SQL bruts, nous utilisons **dbt** (data build tool) pour gÃ©rer la compilation, l'ordre d'exÃ©cution (DAG) et la documentation des requÃªtes.

| Aspect | Description |
|--------|-------------|
| **Organisation** | Chaque requÃªte de crÃ©ation de table est un fichier `.sql` situÃ© dans le dossier `models/` |
| **Configuration Meta** | Pour lier une table SQL Ã  un paramÃ¨tre spÃ©cifique de l'API de gestion (ex: un ID de dataset), nous utilisons la configuration native de dbt directement dans le fichier SQL |

> [!TIP]
> Plus besoin de fichier CSV externe pour la configuration !

---

## 2. Gestion des DÃ©pendances & Environnement (uv)

Le projet utilise [**uv**](https://github.com/astral-sh/uv) pour la gestion des dÃ©pendances Python.

```dockerfile
# Installe les dÃ©pendances dÃ©finies dans uv.lock directement dans l'environnement systÃ¨me du conteneur
RUN uv sync --frozen --no-dev --system
```

| Option | Description |
|--------|-------------|
| `--frozen` | Interdit la mise Ã  jour des versions (respect strict du lockfile) |
| `--no-dev` | N'installe pas les outils de test/dev pour allÃ©ger l'image |
| `--system` | Installe dans l'environnement systÃ¨me (pas de virtualenv) |

---

## 3. SÃ©curitÃ© & Authentification API (Secret Token)

L'appel Ã  l'API de gestion (pour notifier la crÃ©ation des tables) est sÃ©curisÃ© par un **Bearer Token statique**.

> [!CAUTION]
> Ce token ne doit **jamais** apparaÃ®tre en clair dans le code ou les fichiers de configuration.

### Flux de gestion du secret

```mermaid
flowchart LR
    A[Google Secret Manager] -->|monte| B[Cloud Run Job]
    B -->|variable env| C[API_TOKEN]
    C -->|utilisÃ© par| D[Script Python]
```

| Ã‰tape | Description |
|-------|-------------|
| **Stockage** | Le token est stockÃ© dans Google Secret Manager (gÃ©rÃ© par Terraform) |
| **Injection** | Le module Terraform configure le Job Cloud Run pour monter ce secret en tant que variable d'environnement `API_TOKEN` |
| **Source** | Secret Manager (version `latest`) |

### Utilisation dans le Script Python

```python
# Extrait du script
token = os.environ.get("API_TOKEN")
headers = {"Authorization": f"apikey {token}"} if token else {}
```

> [!NOTE]
> Si la variable est vide, le script logue un avertissement mais ne plante pas (sauf si un appel est requis).

---

## 4. Workflow "Generic Runner" (Download-on-Start)

L'architecture sÃ©pare le **code d'exÃ©cution** (Image Docker) des **requÃªtes mÃ©tier** (Fichiers SQL).

```mermaid
sequenceDiagram
    participant CR as Cloud Run Job
    participant GCS as GCS Bucket
    participant BQ as BigQuery
    participant API as API de Gestion

    CR->>GCS: 1. TÃ©lÃ©charge les fichiers .sql
    CR->>CR: 2. Place dans /app/models
    CR->>BQ: 3. dbt run (compile & exÃ©cute)
    CR->>CR: 4. Analyse run_results.json + manifest.json
    CR->>API: 5. Callback pour chaque succÃ¨s
```

### Ã‰tapes dÃ©taillÃ©es

1. **DÃ©marrage & TÃ©lÃ©chargement** : Le script Python se connecte au bucket GCS dÃ©fini par `GCS_BUCKET_NAME` et tÃ©lÃ©charge l'intÃ©gralitÃ© du dossier contenant les requÃªtes `.sql` dans `/app/models`

2. **ExÃ©cution dbt** : Le script lance `dbt run`. dbt compile les fichiers SQL tÃ©lÃ©chargÃ©s et exÃ©cute les transformations sur BigQuery

3. **Analyse & Callback** : Le script croise les rÃ©sultats (`run_results.json`) avec la configuration meta (`manifest.json`). Pour chaque succÃ¨s, il dÃ©clenche l'appel API avec le token sÃ©curisÃ©

---

## 5. Configuration des RequÃªtes SQL

La liaison entre une requÃªte SQL et l'API se fait via la configuration `meta` native de dbt, directement dans le fichier `.sql`.

### Exemple : `models/users.sql`

```sql
{{ config(
    materialized='table',
    meta = {
        "api_trigger_param": "api_param" 
    }
) }}

-- Si api_trigger_param est prÃ©sent, le script appellera : BASE_URL/api/automation/v1.0/datasets/{api_param}/publish/
SELECT ...
```

---

## 6. Le Wrapper Python (L'Orchestrateur)

Le point d'entrÃ©e du conteneur est le script `main.py`.

### Workflow du script

```mermaid
flowchart TD
    A[DÃ©marrage] --> B[dbt run]
    B --> C[Analyse run_results.json + manifest.json]
    C --> D{Table en succÃ¨s ?}
    D -->|Oui| E[RequÃªte GET vers API]
    D -->|Non| F[Log erreur]
    E --> G[Fin]
    F --> G
```

| Ã‰tape | Description |
|-------|-------------|
| **ExÃ©cution** | Lance `dbt run` |
| **Analyse** | Croise les fichiers `run_results.json` (statuts) et `manifest.json` (configs meta) |
| **Notification** | RequÃªte GET vers l'API de gestion pour chaque table en succÃ¨s |
| **Authentification** | Bearer Token lu depuis `API_TOKEN` |

---

## 7. Conteneurisation (Docker)

Le projet est packagÃ© dans une image Docker optimisÃ©e pour Cloud Run.

---

## 8. Infrastructure (Terraform & Cloud Run)

Le dÃ©ploiement est gÃ©rÃ© par un **module Terraform gÃ©nÃ©rique**.

### Ressource principale

- **`google_cloud_run_v2_job`** : Contrairement Ã  un "Service", le "Job" est conÃ§u pour des tÃ¢ches qui ont un dÃ©but et une fin (pas d'Ã©coute de port HTTP)

### Variables d'environnement

| Variable | Description |
|----------|-------------|
| `API_CALLBACK_URL` | L'URL de base de l'API de gestion |
| `API_TOKEN` | Token d'authentification (injectÃ© depuis Secret Manager) |

### Planification

Un **`google_cloud_scheduler_job`** dÃ©clenche le Job Cloud Run Ã  frÃ©quence dÃ©finie (ex: tous les matins Ã  6h).

---

## ðŸ“‚ Structure du projet

```
bq2bq-dbt-docker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py          # Script orchestrateur Python
â”‚   â””â”€â”€ dbt_project.yml  # Configuration dbt
â”œâ”€â”€ Dockerfile           # Image Docker
â”œâ”€â”€ README.md            # Ce fichier
â””â”€â”€ ...
```